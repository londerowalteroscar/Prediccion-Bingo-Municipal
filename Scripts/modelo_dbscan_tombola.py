# ğŸ“¦ ImportaciÃ³n de librerÃ­as
import pandas as pd
import numpy as np
from sklearn.cluster import DBSCAN
from sklearn.preprocessing import StandardScaler
import os

# ğŸ“ Ruta al archivo
ruta_archivo = os.path.join("data", "tombola.xlsx")

# ğŸ“¥ Cargar archivo
df = pd.read_excel(ruta_archivo)
df.dropna(subset=["Numero", "Fecha"], inplace=True)

# ğŸ§¹ Preprocesamiento
df["Fecha"] = pd.to_datetime(df["Fecha"])
df["dia_semana"] = df["Fecha"].dt.dayofweek
df["Numero"] = df["Numero"].astype(int)

# ğŸ“Š Crear tabla dinÃ¡mica: nÃºmero vs. frecuencia por dÃ­a de la semana
tabla = pd.crosstab(df["Numero"], df["dia_semana"])

# âš–ï¸ Escalar los datos
scaler = StandardScaler()
X_scaled = scaler.fit_transform(tabla)

# ğŸ“Œ Aplicar DBSCAN
dbscan = DBSCAN(eps=1.5, min_samples=2)
labels = dbscan.fit_predict(X_scaled)

# â• AÃ±adir etiquetas a los datos
tabla["cluster"] = labels

# ğŸ“¤ Filtrar el cluster principal (el mÃ¡s numeroso que no sea ruido -1)
cluster_counts = tabla["cluster"].value_counts()
cluster_principal = cluster_counts[cluster_counts.index != -1].idxmax()

# ğŸ† Top 10 nÃºmeros mÃ¡s frecuentes dentro del cluster principal
numeros_cluster = tabla[tabla["cluster"] == cluster_principal].drop("cluster", axis=1)
top_10_dbscan = numeros_cluster.sum(axis=1).sort_values(ascending=False).head(10).index.tolist()

# âœ… Resultado
print("ğŸ” PredicciÃ³n por agrupamiento DBSCAN (detectando densidad):")
print(top_10_dbscan)
